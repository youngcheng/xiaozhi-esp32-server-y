import hashlib
import threading
import json
import os, time
from collections import deque
import uuid

from numpy.linalg import norm
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from datetime import datetime
from config.logger import setup_logging
TAG = __name__
# Cosine similarity function
cos_sim = lambda a, b: (a @ b.T) / (norm(a) * norm(b))


import numpy as np

class IntentRecognizer:
    intent_embeddings_cache = {}
    cache_lock = threading.Lock()
    def __init__(self, embedding_model):
        self.logger = setup_logging()
        self.embedding_model = embedding_model
        # å­˜å‚¨æ³¨å†Œçš„æ„å›¾å’Œç›¸ä¼¼åº¦é˜ˆå€¼ä»¥åŠå¯¹åº”çš„å›è°ƒå‡½æ•°
        self.intent_callbacks = []
        
    def register_intent(self, intent_phrases, callback_function, similarity_threshold=0.7):
        """
        æ³¨å†Œä¸€ä¸ªæ„å›¾
        :param intent_phrases: æ„å›¾ç›¸å…³çš„çŸ­è¯­åˆ—è¡¨
        :param callback_function: å¯¹åº”çš„å›è°ƒå‡½æ•°
        :param similarity_threshold: æ„å›¾ä¸æŸ¥è¯¢çš„ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.7
        """
        embed_start = time.time()
        with self.cache_lock:
            for phrase in intent_phrases:
                if phrase not in IntentRecognizer.intent_embeddings_cache:
                    # è®¡ç®—åµŒå…¥å¹¶ç¼“å­˜
                    intent_embedding = self.embedding_model.encode([phrase])[0]
                    IntentRecognizer.intent_embeddings_cache[phrase] = intent_embedding
                else:
                    intent_embedding = IntentRecognizer.intent_embeddings_cache[phrase]

                self.intent_callbacks.append({
                    "phrase": phrase,
                    "embedding": intent_embedding,
                    "callback": callback_function,
                    "threshold": similarity_threshold
                })
        embed_time = time.time() - embed_start
        if embed_time > 0.1:  # åªè®°å½•è¶…è¿‡0.1ç§’çš„åµŒå…¥è®¡ç®—
            self.logger.bind(tag=TAG).info(f"æ„å›¾çŸ­è¯­åµŒå…¥è®¡ç®—è€—æ—¶: {embed_time:.2f}ç§’")

    def handle_query(self, query: str, *args, **kwargs):
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œè°ƒç”¨åŒ¹é…çš„å›è°ƒå‡½æ•°
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param args: ä»»æ„ä½ç½®å‚æ•°ä¼ é€’ç»™å›è°ƒå‡½æ•°
        :param kwargs: ä»»æ„å…³é”®å­—å‚æ•°ä¼ é€’ç»™å›è°ƒå‡½æ•°
        :return: å›è°ƒå‡½æ•°çš„è¿”å›å€¼
        """
        query = query.strip()
        # è®¡ç®—ç”¨æˆ·æŸ¥è¯¢çš„åµŒå…¥è¡¨ç¤º
        query_embedding = self.embedding_model.encode([query])[0]
        
        best_match = None
        highest_similarity = -1
        matched_callback = None

        # æ¯”è¾ƒæŸ¥è¯¢ä¸æ³¨å†Œçš„æ„å›¾çŸ­è¯­çš„ç›¸ä¼¼åº¦
        for intent in self.intent_callbacks:
            similarity = np.dot(query_embedding, intent["embedding"]) / (np.linalg.norm(query_embedding) * np.linalg.norm(intent["embedding"]))
            if similarity > highest_similarity and similarity >= intent["threshold"]:
                highest_similarity = similarity
                best_match = intent["phrase"]
                matched_callback = intent["callback"]

        if best_match and matched_callback:
            # è°ƒç”¨ä¸åŒ¹é…æ„å›¾å¯¹åº”çš„å›è°ƒå‡½æ•°ï¼Œä¼ é€’ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
            self.logger.bind(tag=TAG).info(f"{query}\tæ„å›¾è¯†åˆ«ç»“æœï¼š{best_match}\tfunc:{matched_callback}\t (ç›¸ä¼¼åº¦: {highest_similarity:.2f})")
            return matched_callback(query,*args, **kwargs)
        self.logger.bind(tag=TAG).info(f"{query}\tæœªè¯†åˆ«åˆ°æ„å›¾")
        return None






class MemoryManager:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(MemoryManager, cls).__new__(cls)  
        return cls._instance

    def __init__(
            self,
            llm,
            embd,
            summary_prompt: str = "è¯·æ€»ç»“ä¸‹é¢çš„èŠå¤©å†…å®¹,å¿…é¡»åœ¨{content_len}å­—æ•°ä»¥å†…ï¼Œå¿…é¡»åŒ…å«èŠå¤©çš„å®Œæ•´ç»†èŠ‚:\n\n{content}",
            max_memory_length: int = 1000,
            summary_length: int = 1000,
            max_summary_length: int = 2000,
            memory_dir='memory_data',
            use_intent_recognition: bool = False  # æ·»åŠ æ„å›¾è¯†åˆ«å¼€å…³
        ):
        start_time = time.time()
        self.logger = setup_logging()
        self.use_intent_recognition = use_intent_recognition
        
        # åŸºç¡€é…ç½®åˆå§‹åŒ–
        self._init_basic_config(llm, embd, summary_prompt, max_memory_length, summary_length, max_summary_length, memory_dir)
        
        # åŠ è½½è®°å¿†æ•°æ®
        memory_start = time.time()
        self.load_memory()
        memory_time = time.time() - memory_start
        if memory_time > 0.1:  # åªè®°å½•è¶…è¿‡0.1ç§’çš„åŠ è½½æ—¶é—´
            self.logger.bind(tag=TAG).info(f"è®°å¿†æ•°æ®åŠ è½½è€—æ—¶: {memory_time:.2f}ç§’")
        
        # ä»…åœ¨å¯ç”¨æ„å›¾è¯†åˆ«æ—¶åˆå§‹åŒ–
        if self.use_intent_recognition:
            intent_start = time.time()
            self._init_intent_recognizer()
            intent_time = time.time() - intent_start
            if intent_time > 0.1:  # åªè®°å½•è¶…è¿‡0.1ç§’çš„åˆå§‹åŒ–æ—¶é—´
                self.logger.bind(tag=TAG).info(f"æ„å›¾è¯†åˆ«å™¨åˆå§‹åŒ–è€—æ—¶: {intent_time:.2f}ç§’")
        
        total_time = time.time() - start_time
        if total_time > 0.1:  # åªè®°å½•è¶…è¿‡0.1ç§’çš„æ€»æ—¶é—´
            self.logger.bind(tag=TAG).info(f"è®°å¿†ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

    def _init_basic_config(self, llm, embd, summary_prompt, max_memory_length, summary_length, max_summary_length, memory_dir):
        """åˆå§‹åŒ–åŸºç¡€é…ç½®"""
        self.max_memory_length = max_memory_length
        self.summary_length = summary_length
        self.max_summary_length = max_summary_length

        self.memory_data = {}  # ç”¨å­—å…¸ç®¡ç†æ¯ä¸ªç”¨æˆ·çš„è®°å¿†
        self.lock = threading.Lock()  # é”å¯¹è±¡ï¼Œç”¨äºçº¿ç¨‹åŒæ­¥
        self.summary_prompt = summary_prompt
        self.llm = llm
        self.embedding_model = embd  # ç”¨äºç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥
        self.memory_dir = memory_dir
        self.executor = ThreadPoolExecutor()
        
        if not os.path.exists(self.memory_dir):
            os.makedirs(self.memory_dir,exist_ok=True)  # åˆ›å»ºç›®å½•
        
        # ç¡®ä¿ç›®å½•å…·æœ‰è¯»å†™æƒé™
        if not os.access(self.memory_dir, os.W_OK):
            try:
                os.chmod(self.memory_dir, 0o700)  # è®¾ç½®è¯»å†™æƒé™
            except Exception as e:
                self.logger.bind(tag=TAG).warning(f"ç›®å½•æƒé™è®¾ç½®å¤±è´¥: {e}")
                raise PermissionError(f"æ²¡æœ‰è¶³å¤Ÿæƒé™è®¿é—®ç›®å½•: {self.memory_dir}")

    def _init_intent_recognizer(self):
        """åˆå§‹åŒ–æ„å›¾è¯†åˆ«å™¨"""
        model_load_start = time.time()
        self.intent_recognizer = IntentRecognizer(self.embedding_model)
        model_load_time = time.time() - model_load_start
        if model_load_time > 0.1:
            self.logger.bind(tag=TAG).info(f"æ„å›¾è¯†åˆ«å™¨æ¨¡å‹åŠ è½½è€—æ—¶: {model_load_time:.2f}ç§’")

        intent_register_start = time.time()
        self.intent_recognizer.register_intent(
            ["å›å¿†å¯¹è¯", "å›å¿†ä¸Šæ¬¡è®²çš„", "è¯·å›å¿†","æœ‰ä»€ä¹ˆè®°å¿†","åˆšæ‰è®²äº†ä»€ä¹ˆ","ä¸Šæ¬¡è®²äº†ä»€ä¹ˆ"], 
            self._recall_last_conversation, 
            similarity_threshold=0.7
        )
        self.logger.bind(tag=TAG).info(f"æ„å›¾çŸ­è¯­æ³¨å†Œå®Œæˆ: å›å¿†å¯¹è¯, è€—æ—¶: {time.time() - intent_register_start:.2f}ç§’")
        self.intent_recognizer.register_intent(
            ["åˆ é™¤æˆ‘çš„è®°å¿†","åˆ é™¤æ‰€æœ‰è®°å¿†"], 
            self._del_all, 
            similarity_threshold=0.9
        )
        intent_register_time = time.time() - intent_register_start
        if intent_register_time > 0.1:
            self.logger.bind(tag=TAG).info(f"æ„å›¾çŸ­è¯­æ³¨å†Œè€—æ—¶: {intent_register_time:.2f}ç§’")

    def _recall_last_conversation(self,query: str, token_name: str)->str:
        """
        å›å¿†ä¸Šæ¬¡çš„å¯¹è¯
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: ä¸Šæ¬¡çš„å¯¹è¯å†…å®¹
        """
        user_memory = self.search_memory(token_name, query, top_k=5)
        

        if len(user_memory) == 0:
            
            user_memory = self.memory_data.get(token_name, {'memory':[]})
            
            user_memory = list(user_memory['memory'])
            user_memory = user_memory[-10:]        

            

        output = "\n".join([msg['content'] for msg in user_memory])

        
        return f"{query}\n\næˆ‘ä»¬ä¸Šæ¬¡èŠåˆ°äº†:\n\n{output}"

    def _generate_summary(self, chat_paragraph: list):
        """
        ç”ŸæˆèŠå¤©å†…å®¹çš„æ€»ç»“ï¼ˆå¯ä»¥æ ¹æ®å…·ä½“è¦æ±‚å®šåˆ¶æ€»ç»“é€»è¾‘ï¼‰
        :param chat_content: èŠå¤©å†…å®¹
        :return: æ€»ç»“çš„å­—ç¬¦ä¸²
        """
        #self.logger.bind(tag=TAG).info(f"ç”Ÿæˆè®°å¿†æ‘˜è¦: {chat_paragraph}")
        if self.llm is None:
            return "".join([msg['content'] for msg in chat_paragraph])[:self.summary_length]
        
        response_message = []
        try:            
            content = self.summary_prompt.format(content=json.dumps(chat_paragraph, ensure_ascii=False),content_len=self.summary_length)
            #content= f'''æ€»ç»“{self.summary_length}å­—ä»¥å†…çš„å¯¹è¯æ‘˜è¦ï¼Œå°†å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯ä½œä¸ºè®°å¿†å­˜å‚¨ä¸‹æ¥ï¼Œä½¿ä½ æ›´äº†è§£ä½ çš„å¯¹è¯å¯¹è±¡ã€‚ å¯¹è¯å†…å®¹å¦‚ä¸‹{json.dumps(chat_paragraph)}'''
            self.logger.bind(tag=TAG).info(f"LLM è¯·æ±‚å†…å®¹ ç”Ÿæˆè®°å¿†æ‘˜è¦: {content}")

            #self.logger.bind(tag=TAG).info(f"LLM è¯·æ±‚å†…å®¹ ç”Ÿæˆè®°å¿†æ‘˜è¦: {content}")
            llm_responses = self.llm.response(
                str(uuid.uuid4()), 
                [
                    {
                        "role": "user", 
                        "content": content
                    }
                ]
            )
        except Exception as e:
            self.logger.bind(tag=TAG).warning(f"LLM å¤„ç†å‡ºé”™ {e}")
            return None

        for content in llm_responses:
            response_message.append(content)
        return "".join(response_message)

    def _forget_old_memory(self, token_name: str):
        """
        è¶…è¿‡æœ€å¤§è®°å¿†æ€»é•¿åº¦æ—¶ï¼Œåˆ é™¤ä¸é‡è¦çš„è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        user_memory = self.memory_data.get(token_name, {'memory': deque(), 'total_length': 0})

        while user_memory['total_length'] > self.max_memory_length and user_memory['memory']:
            # åˆ é™¤æœ€æ—§çš„èŠå¤©å†…å®¹å’Œå¯¹åº”çš„åµŒå…¥
            oldest_message = user_memory['memory'].popleft()
            oldest_embedding = user_memory['embeddings'].popleft()  # Remove corresponding embedding
            user_memory['total_length'] -= len(oldest_message['content'])



    def _update_summary(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ›´æ–°è®°å¿†æ€»ç»“ï¼Œåˆå¹¶æ¯ä¸ªèŠå¤©æ®µè½çš„å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """      
        self.logger.bind(tag=TAG).info(f"æ›´æ–°è®°å¿†æ€»ç»“: {token_name}, len(chat_paragraph): {len(chat_paragraph)}")
        if len(chat_paragraph) == 0:
            return 
        
        summary = self._generate_summary(chat_paragraph)

        if summary is None or len(summary.strip()) == 0:
            return
        
        self.memory_data[token_name].setdefault('memory_summary', []).append(summary)

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        if self.use_intent_recognition:
            summary_embedding = self.embedding_model.encode([summary])[0]
            self.memory_data[token_name].setdefault('summary_embeddings', []).append(summary_embedding)

    def _combine_summary(self, token_name: str):
        """
        å°†æ‰€æœ‰çš„è®°å¿†æ€»ç»“åˆå¹¶ä¸ºä¸€ä¸ª
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})

        # å¦‚æœæ²¡æœ‰è¶…è¿‡æœ€å¤§æ€»ç»“é•¿åº¦ï¼Œç›´æ¥è¿”å›
        old_summary = "".join(user_memory['memory_summary'])
        if len(user_memory) == 0 or len(old_summary) < self.max_memory_length:
            self.logger.bind(tag=TAG).debug("ä¸éœ€è¦åˆå¹¶,æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
            return
        self.logger.bind(tag=TAG).debug("åˆå¹¶å‰çš„æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
        summary = self._generate_summary(user_memory['memory_summary'])
        self.logger.bind(tag=TAG).debug("åˆå¹¶åçš„æ€»ç»“é•¿åº¦ï¼š", len(summary))
        self.memory_data[token_name]['memory_summary'] = [summary]

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        if self.use_intent_recognition:
            summary_embedding = self.embedding_model.encode([summary])[0]
            self.memory_data[token_name]['summary_embeddings'] = [summary_embedding]

    def _del_all(self, query:str, token_name: str)->str:
        """
        åˆ é™¤æ‰€æœ‰è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}
        self.save_memory()
        return f"ä½ å¿…é¡»{query}\n\nä½ å¿…é¡»å›ç­”åŒæ„åˆ é™¤æ‰€æœ‰è®°å¿†"

    async def add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ·»åŠ ä¸€æ®µèŠå¤©å†…å®¹åˆ°è®°å¿†ä¸­
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param chat_paragraph: èŠå¤©æ®µè½ï¼ŒåŒ…å«å¤šæ¡èŠå¤©è®°å½•
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, self._add_chat_paragraph, token_name, chat_paragraph)

    def _add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        with self.lock:  # ä½¿ç”¨é”ä¿è¯çº¿ç¨‹å®‰å…¨
            if token_name not in self.memory_data:
                self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}

            user_memory = self.memory_data[token_name]
            new_embeddings = []

            for message in chat_paragraph:
                role = message['role']
                content = message['content']

                chat_hash = hashlib.md5(content.encode()).hexdigest()

                user_memory['memory'].append({"role": role, "content": content, "hash": chat_hash, "datatime": "{:%Y-%m-%d %H:%M:%S}".format(datetime.now())})
                user_memory['total_length'] += len(content)

                if self.use_intent_recognition:
                    # ç”ŸæˆåµŒå…¥
                    embedding = self.embedding_model.encode([content])[0]  # ä½¿ç”¨åµŒå…¥æ¨¡å‹ç”ŸæˆåµŒå…¥
                    user_memory['embeddings'].append(embedding)

            # æ›´æ–°è®°å¿†æ€»ç»“
            self._update_summary(token_name, chat_paragraph)

            # å¦‚æœè®°å¿†è¶…å‡ºäº†é™åˆ¶ï¼Œåˆ é™¤ä¸é‡è¦çš„å†…å®¹
            self._forget_old_memory(token_name)

            # åˆå¹¶å‹ç¼©è®°å¿†æ€»ç»“
            self._combine_summary(token_name)

            # ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶
            self.save_memory()

    def handle_user_scene(self,token_name:str, query: str) -> str:
        """
        è§£æç”¨æˆ·æŸ¥è¯¢ï¼Œæ ¹æ®å¼€å…³å†³å®šæ˜¯å¦ä½¿ç”¨æ„å›¾è¯†åˆ«
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: å¤„ç†åçš„æŸ¥è¯¢
        """
        query = query.strip()
        if len(query) == 0:
            return query
        
        if self.use_intent_recognition:
            # ä½¿ç”¨æ„å›¾è¯†åˆ«
            result = self.intent_recognizer.handle_query(query, token_name)
            if result is not None:
                return result
        
        # å½“æ„å›¾è¯†åˆ«å…³é—­æˆ–æœªè¯†åˆ«åˆ°æ„å›¾æ—¶ï¼Œä½¿ç”¨è®°å¿†æ€»ç»“
        self.logger.bind(tag=TAG).info(f"æœªè¯†åˆ«åˆ°æ„å›¾ï¼Œä½¿ç”¨è®°å¿†æ€»ç»“: {query}")
        similar_summary = self.search_memory_summary(token_name, query, top_k=1, threshold=0.5)
        if similar_summary:
            return f"{query}\n\næ ¹æ®è®°å¿†ï¼Œæˆ‘ä»¬ä¹‹å‰èŠåˆ°ï¼š\n\n{similar_summary[0]}"
        self.logger.bind(tag=TAG).info(f"æœªæ‰¾åˆ°è®°å¿†æ€»ç»“: {query}")
        return query
    

    def get_memory_summary(self, token_name: str) -> str:
        """
        è·å–å½“å‰ç”¨æˆ·çš„è®°å¿†æ€»ç»“
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ€»ç»“
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})
        return "\n\n".join(user_memory['memory_summary'])

    def get_full_memory(self, token_name: str) -> list[str]:
        """
        è·å–å½“å‰ç”¨æˆ·çš„å®Œæ•´è®°å¿†å†…å®¹
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ‰€æœ‰è®°å¿†å†…å®¹
        """
        user_memory = self.memory_data.get(token_name, {'memory': []})
        return [msg['content'] for msg in user_memory['memory']]

    def search_memory(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'embeddings': []})
        if not user_memory['embeddings']:
            return []

        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†ä¸­æ¯æ¡æ¶ˆæ¯çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_memory = [user_memory['memory'][i] for i in top_indices]

        return similar_memory

    def search_memory_summary(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': [], 'summary_embeddings': []})
        
        if not self.use_intent_recognition and user_memory.get('memory_summary') is not None and len(user_memory['memory_summary']) > 0:
            self.logger.bind(tag=TAG).info(f"ä¸ä½¿ç”¨æ„å›¾è¯†åˆ«ï¼Œç›´æ¥è¿”å›è®°å¿†æ€»ç»“,{user_memory['memory_summary']}")
            #åˆå¹¶æ‰€æœ‰çš„è®°å¿†æ€»ç»“
            all_summary = "\n\n".join(user_memory['memory_summary'])
            return [all_summary]
        
        if user_memory.get('summary_embeddings') is None or len(user_memory['summary_embeddings']) == 0:
            return []
        
        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†æ€»ç»“çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['summary_embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_summary = [user_memory['memory_summary'][i] for i in top_indices]

        return similar_summary

    def _sanitize_filename(self, filename: str) -> str:
        """
        å°†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        :param filename: åŸå§‹æ–‡ä»¶å
        :return: å®‰å…¨çš„æ–‡ä»¶å
        """
        # æ›¿æ¢Windowsç³»ç»Ÿä¸­çš„éæ³•å­—ç¬¦ \ / : * ? " < > |
        illegal_chars = ['\\', '/', ':', '*', '?', '"', '<', '>', '|']
        for char in illegal_chars:
            filename = filename.replace(char, '_')
        return filename

    def _restore_token_name(self, filename: str) -> str:
        """
        è¿˜åŸtokenåç§°ï¼Œå°†ä¸‹åˆ’çº¿è¿˜åŸä¸ºå†’å·
        :param filename: æ–‡ä»¶ç³»ç»Ÿå®‰å…¨çš„æ–‡ä»¶å
        :return: åŸå§‹tokenåç§°
        """
        return filename.replace('_', ':')

    def save_memory(self):
        """
        å°†è®°å¿†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä»¥token_nameä½œä¸ºæ–‡ä»¶å
        """
        try:
            self.logger.bind(tag=TAG).info("å¼€å§‹ä¿å­˜è®°å¿†")
            for token_name, user_data in self.memory_data.items():
                self.logger.bind(tag=TAG).debug(f"ä¿å­˜è®°å¿†æ•°æ®ï¼š{token_name}:{user_data}")
                memory_data_serializable = {
                    'memory': list(user_data['memory']),
                    'total_length': user_data['total_length'],
                    'memory_summary': user_data['memory_summary'],
                }
                if self.use_intent_recognition:
                    memory_data_serializable['summary_embeddings'] = [embedding.tolist() for embedding in user_data['summary_embeddings']]
                    memory_data_serializable['embeddings'] = [embedding.tolist() for embedding in user_data['embeddings']]
                
                # ä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶å
                safe_token_name = self._sanitize_filename(token_name)
                file_path = os.path.join(self.memory_dir, f"{safe_token_name}.json")
                
                self.logger.bind(tag=TAG).debug(f"ä¿å­˜è®°å¿†è‡³ {file_path}")
                with open(file_path, 'w', encoding='utf-8') as file:
                    json.dump(memory_data_serializable, file, ensure_ascii=False, indent=4)
                self.logger.bind(tag=TAG).info(f"è®°å¿†å·²ä¿å­˜è‡³ {file_path}")

        except Exception as e:
            self.logger.bind(tag=TAG).warning(f"ä¿å­˜è®°å¿†æ—¶å‡ºé”™: {e}")

    def load_memory(self):
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½è®°å¿†æ•°æ®
        """
        try:
            self.memory_data = {}

            for file_name in os.listdir(self.memory_dir):
                if file_name.endswith('.json'):
                    sanitized_token = file_name[:-5]  # å»æ‰ .json åç¼€
                    token_name = self._restore_token_name(sanitized_token)  # è¿˜åŸåŸå§‹tokenåç§°
                    file_path = os.path.join(self.memory_dir, file_name)

                    with open(file_path, 'r', encoding='utf-8') as file:
                        try:
                            memory_data = json.load(file)
                        except Exception as e:
                            self.logger.bind(tag=TAG).warning(f"åŠ è½½è®°å¿†{file_path}æ—¶å‡ºé”™: {e}")                         
                            continue

                        self.memory_data[token_name] = {
                            'memory': deque(memory_data['memory']),
                            'total_length': memory_data['total_length'],
                            'memory_summary': memory_data['memory_summary'],
                            #'summary_embeddings': [np.array(embedding) for embedding in memory_data['summary_embeddings']],
                            #'embeddings': deque([np.array(embedding) for embedding in memory_data['embeddings']])
                        }
                        if self.use_intent_recognition:
                            self.memory_data[token_name]['summary_embeddings'] = deque([np.array(embedding) for embedding in memory_data['summary_embeddings']])
                            self.memory_data[token_name]['embeddings'] = deque([np.array(embedding) for embedding in memory_data['embeddings']])
                    self.logger.bind(tag=TAG).info(f"è®°å¿†å·²ä» {file_path} åŠ è½½")

        except Exception as e:
            self.logger.bind(tag=TAG).warning(f"åŠ è½½è®°å¿†æ—¶å‡ºé”™: {e}")
            

if __name__ == '__main__':
    from sentence_transformers import SentenceTransformer
    # ç¤ºä¾‹ä½¿ç”¨
    embedding_model = SentenceTransformer('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True, device="cpu")
    # ä¸ä½¿ç”¨æ„å›¾è¯†åˆ«çš„ç¤ºä¾‹
    memory_manager = MemoryManager(
        llm=None, 
        embd=embedding_model, 
        max_memory_length=100,
        use_intent_recognition=False  # ç¦ç”¨æ„å›¾è¯†åˆ«
    )

    # æ¨¡æ‹Ÿä¸¤æ®µå¯¹è¯
    chat_paragraph1 = [
        {"role": "user", "content": "å¹åˆ°äº†ä½ çš„å‘ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "å‘ä¸è½»æ‹‚ï¼Œç‹¬æ€œæ­¤é™…ï¼Œæ¢¦æ–­è°å®¶ï¼ŸğŸ˜”"}
    ]

    chat_paragraph2 = [
        {"role": "user", "content": "ä»Šå¤©å¤©æ°”ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "æ™´å¤©ï¼ŸğŸ˜”"}
    ]

    # æ·»åŠ ç¬¬ä¸€æ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph1))

    # æ·»åŠ ç¬¬äºŒæ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph2))

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
    query = "ä»Šå¤©å¤©æ°”?"
    similar_memory = memory_manager.search_memory("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†å†…å®¹ï¼š", [msg['content'] for msg in similar_memory])

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
    similar_summary = memory_manager.search_memory_summary("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“ï¼š", similar_summary)
